# ğŸ” POMDP Gridworld Learning Framework

æœ¬é¡¹ç›®æ—¨åœ¨é€šè¿‡æ„å»ºä¸€ç³»åˆ—é€æ­¥å¤æ‚åŒ–çš„ Gridworld ç¯å¢ƒï¼Œç³»ç»Ÿå­¦ä¹ ä¸å®ç°ä» **MCTS â†’ POMDP â†’ POMCP** çš„å®Œæ•´æŠ€æœ¯æ ˆã€‚

é¡¹ç›®æœ€ç»ˆç›®æ ‡æ˜¯ä½¿ç”¨ POMCP æ™ºèƒ½ä½“ï¼Œåœ¨ä¸€ä¸ªå«æœ‰é’¥åŒ™ã€æ€ªç‰©ã€é—¨çš„éƒ¨åˆ†å¯è§‚æµ‹ Gridworld ä¸­è¿›è¡Œè§„åˆ’ä¸å†³ç­–ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„

```

pomdp_mcts_learning/
â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å—ï¼ˆç¯å¢ƒ + Agent + ç®—æ³•ï¼‰
â”‚   â”œâ”€â”€ env.py
â”‚   â”œâ”€â”€ mcts.py
â”‚   â”œâ”€â”€ pomcp.py
â”‚   â”œâ”€â”€ belief.py
â”‚   â”œâ”€â”€ agent.py
â”‚   â””â”€â”€ **init**.py
â”‚
â”œâ”€â”€ utils/              # å·¥å…·æ¨¡å—ï¼ˆè¯„ä¼°ã€ç»˜å›¾ã€å®éªŒåŸºç±»ç­‰ï¼‰
â”‚   â”œâ”€â”€ base_experiment.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ trajectory_replay.py
â”‚   â””â”€â”€ metrics_plotter.py
â”‚
â”œâ”€â”€ notebooks/          # Jupyter Notebook å­¦ä¹ ç¬”è®°
â”‚   â”œâ”€â”€ 01_mcts_workflow.ipynb
â”‚   â”œâ”€â”€ 02_belief_update_demo.ipynb
â”‚   â”œâ”€â”€ 03_pomcp_visualization.ipynb
â”‚   â””â”€â”€ 04_comparative_analysis.ipynb
â”‚
â”œâ”€â”€ results/            # å®éªŒè¾“å‡º JSONï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ scripts/            # è„šæœ¬ï¼ˆå¯é€‰ï¼Œç”¨äºæ‰¹é‡è¿è¡Œï¼‰
â””â”€â”€ README.md

````

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–ï¼ˆå¯é€‰ï¼‰

æœ¬é¡¹ç›®æ— é‡ä¾èµ–ï¼Œæ ¸å¿ƒä¾èµ–ä»…ï¼š

```bash
pip install numpy matplotlib
````

---

### 2. è¿è¡Œ MCTS Agent ç¤ºä¾‹ï¼ˆå®Œå…¨å¯è§‚æµ‹ï¼‰

```python
from core import DeterministicGridworld, MCTSAgent

env = DeterministicGridworld()
agent = MCTSAgent(env)

obs = env.reset()
done = False

while not done:
    env.render()
    action = agent.act(obs)
    obs, reward, done = env.step(action)
```

---

## ğŸ“Š å®éªŒæ–¹å¼

### âœ… ä½¿ç”¨ Notebook è¿›è¡Œå®éªŒä¸åˆ†æï¼š

| Notebook                        | å†…å®¹                                |
| ------------------------------- | --------------------------------- |
| `01_mcts_workflow.ipynb`        | MCTS å‚æ•°è°ƒä¼˜ä¸æ€§èƒ½åˆ†æ                    |
| `02_belief_update_demo.ipynb`   | POMDP ä¸­è§‚æµ‹å™ªå£°å½±å“åˆ†æ                   |
| `03_pomcp_visualization.ipynb`  | ç²’å­å˜åŒ–ä¸ä¿¡å¿µåˆ†æ                         |
| `04_comparative_analysis.ipynb` | å¤šæ™ºèƒ½ä½“å¯¹æ¯”å®éªŒï¼ˆPOMCP vs MCTS vs Randomï¼‰ |

---

## ğŸ“ æ”¯æŒæŒ‡æ ‡

æ¯è½®å®éªŒå¯ç”Ÿæˆå¦‚ä¸‹æŒ‡æ ‡ï¼š

* âœ… æˆåŠŸç‡ (`success_rate`)
* âœ… å¹³å‡å¥–åŠ± (`avg_reward`)
* âœ… å¹³å‡æ­¥æ•° (`avg_steps`)
* âœ… è§„åˆ’æ—¶é—´ (`avg_time`)
* â³ ä¿¡å¿µè¯¯å·®ï¼ˆå¯æ‰©å±•ï¼‰
* âœ… JSON ä¿å­˜ + å¯è§†åŒ–

---

## ğŸ§  æ¨¡å—æ”¯æŒæ¦‚è§ˆ

| æ¨¡å—                   | åŠŸèƒ½                                            |
| -------------------- | --------------------------------------------- |
| `env.py`             | å¤šç§ Gridworld ç¯å¢ƒï¼ˆDeterministic / POMDP / æ€ªç‰©ä¸–ç•Œï¼‰ |
| `mcts.py`            | é€šç”¨ MCTS / UCT æœç´¢å™¨                             |
| `pomcp.py`           | åŸºäºå†å²ä¸ç²’å­çš„ POMCP ç®—æ³•                             |
| `belief.py`          | ç²’å­æ»¤æ³¢å™¨ + è§‚æµ‹æ¨¡å‹                                  |
| `agent.py`           | Agent å°è£…ï¼ˆMCTS / POMCP / Greedy / Randomï¼‰      |
| `base_experiment.py` | æ‰¹é‡å®éªŒè¿è¡Œæ¡†æ¶                                      |
| `metrics.py`         | æŒ‡æ ‡è®°å½•ä¸å¯¹æ¯”å›¾ç»˜åˆ¶                                    |

---

## ğŸ§© æ‰©å±•å»ºè®®

* åŠ å…¥ Q-MDPã€DESPOTã€BAMCP ç­‰è¿‘ä¼¼æˆ–å¼ºåŒ–ç­–ç•¥
* ç»“åˆ Gym API æ¥å…¥ RLlib æˆ– PyTorch è®­ç»ƒæ¡†æ¶
* å¢åŠ é«˜ç»´ Gridworldï¼ˆå¦‚å¸¦é¢œè‰²ã€å¤šä¸ªç‰©ä½“ç­‰ï¼‰
* å¤šæ™ºèƒ½ä½“å¯¹æŠ— / åä½œ Gridworld åœºæ™¯

---

## ğŸ“š å‚è€ƒèµ„æº

* Silver et al., [POMCP: Partially Observable Monte Carlo Planning](https://www.cs.ubc.ca/~poole/cs532/2011/readings/silver-uctpomdp.pdf)
* AI Planning Resources: [http://ai-planning.org/](http://ai-planning.org/)
* [Partially Observable Markov Decision Processes](https://en.wikipedia.org/wiki/Partially_observable_Markov_decision_process)

---

## Â© License

For educational use. Feel free to fork and build upon it!


---